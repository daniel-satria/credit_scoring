{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Outline**\n",
    "\n",
    "1. Review - Cross Validation and Model Selection\n",
    "2. Cross Validation\n",
    "3. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data manipulation package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Load data visualization package\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Resampling Methods**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 Validation Set Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**:\n",
    "1.  Randomly divide n observations to training set and validation set or hold-out set.\n",
    "2. The model is fit on the training set.\n",
    "3. Asses the model performance (Deviance or Pseudo R-squared) on the validation set.\n",
    "\n",
    "<center>\n",
    "<img src=\"../assets/validation_set_approach.jpg\" width = 500>\n",
    "</center>\n",
    "\n",
    "**Potential drawbacks**:\n",
    "1. The model performance rate can be highly variable.\n",
    "2. Validation set performance may tend to overestimate performance for the model fit on the entire data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2 Leave-One-Out Cross-Validation (LOOCV)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**:\n",
    "1. Split n observations into a training set containing all but one observation.\n",
    "2. Validation set is that one observation.\n",
    "\n",
    "<center>\n",
    "<img src=\"../assets//loocv.jpg\" width = 500>\n",
    "</center>\n",
    "\n",
    "3. Model performance is estimated by averaging the n resulting assessment.\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(n)}=\\frac{1}{n}\\sum_{i=1}^{n}\\text{AIC}_{(i)}\n",
    "$$\n",
    "\n",
    "**Potential drawbacks**:\n",
    "1. There is no randomness in the training/validation set splits;\n",
    "performing LOOCV multiple times will always yield the same result.\n",
    "2. Expensive to implement, since the model has to be fit n times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3 k-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**:\n",
    "1. Randomly divide n observations into $k$ groups ($k$ folds) of approximately equal size,\n",
    "typically $k=5$ or $k=10$.\n",
    "2. Choose one fold as a validation set,\n",
    "and the remainder $k-1$ folds as training set.\n",
    "\n",
    "<center>\n",
    "<img src=\"../assets/k-fold.jpg\" width = 500>\n",
    "</center>\n",
    "\n",
    "3. Fit model in training set,\n",
    "assess the fitted model in validation set.\n",
    "Repeat step 2 and 3 until $k$ times.\n",
    "4. The $k$-fold CV estimate is computed\n",
    "by averaging model performance\n",
    "from step 3.\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(k)}=\\frac{1}{k}\\sum_{i=1}^{k}\\text{AIC}_{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "From the same data set, 10 times validation set approach produces highly variable model performance.\n",
    "\n",
    "<center>\n",
    "<img src=\"../assets/validation_set_approach_.jpg\" width = 500>\n",
    "</center>\n",
    "\n",
    "But we can see less variability from the 10-fold CV result.\n",
    "\n",
    "<center>\n",
    "<img src=\"../assets/10_fold_CV.jpg\" width = 500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Variable Selection Methods**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1 Best Subset Selection**\n",
    "Fit a separate model for each possible combination of the $p$ predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**:\n",
    "1.  Begin with fitting $M_{0}$, the null model that only  contains intercept $\\beta_{0}$.\n",
    "2. For $k = 1,2,\\dots,p$ :\n",
    "  - Fit all $\\binom{p}{k}$ models that contain exactly $k$ predictors.\n",
    "  - Pick the best among those models by the best CV score, and call it $M_{k}$.\n",
    "3. Select a single best model from among $M_{0}, \\dots, M_{p}$ by the best CV score.\n",
    "\n",
    "**Potential drawbacks**:\n",
    "- In general, there are $2^{p}$ possible predictors combination for $p$ predictors.\n",
    "- So if $p = 10$ predictors, there are approximately 1,000 possible models to be fitted.\n",
    "- If $p = 20$ predictors, then there are over one million possibilities!\n",
    "- The number of possible models that must be considered grows rapidly as $p$ increases.\n",
    "- Best subset selection becomes computationally infeasible for values of $p$ greater than around 40, even with extremely fast modern computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2 Forward Selection**\n",
    "Begin with null model (no predictors), then adds predictors that gives the greatest additional improvement to the model, one-at-a-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**:\n",
    "1.  Begin with fitting $M_{0}$, the null model that only  contains intercept $\\beta_{0}$.\n",
    "2. For $k = 0,\\dots,p-1$ :\n",
    "  - Consider all $p−k$ models that augment the predictors in $M_{k}$ with one additional predictor.\n",
    "  - Choose the best among those $p−k$ models by the best CV score and call it $M_{k+1}$.\n",
    "3. Select a single best model from among $M_{0}, \\dots, M_{p}$ by the best CV score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3 Backward Elimination**\n",
    "Begin with the full model containing all p predictors,\n",
    "and then iteratively removes the least useful predictor, one-at-a-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**:\n",
    "1.  Begin with fitting $M_{p}$, the full model, which contains all $p$ predictors.\n",
    "2. For $k = p,p-1\\dots,1$ :\n",
    "  - Consider all $k$ models that contain all but one of the predictors in $M_{k}$, for a total of $k−1$ predictors.\n",
    "  - Choose the best among these $k$ models by the best CV score and call it $M_{k-1}$.\n",
    "3. Select a single best model from among $M_{0}, \\dots, M_{p}$ by the best CV score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spine</th>\n",
       "      <th>Width</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Satellite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Color  Spine  Width  Weight  Satellite\n",
       "0      0      2      3   28.3    3.05          8\n",
       "1      1      3      3   26.0    2.60          4\n",
       "2      2      3      3   25.6    2.15          0\n",
       "3      3      4      2   21.0    1.85          0\n",
       "4      4      2      3   29.0    3.00          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset from csv file\n",
    "data = pd.read_csv('../data/horseshoe_crab.csv')\n",
    "\n",
    "# Table check\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   index      173 non-null    int64  \n",
      " 1   Color      173 non-null    int64  \n",
      " 2   Spine      173 non-null    int64  \n",
      " 3   Width      173 non-null    float64\n",
      " 4   Weight     173 non-null    float64\n",
      " 5   Satellite  173 non-null    int64  \n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 8.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Information check\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset has **173 observations** from **5 variables**:\n",
    "  - `Color` : multicategory (ordinal)\n",
    "  - `Spine` : multicategory (nominal)\n",
    "  - `Width` : continuous\n",
    "  - `Weight` : continuous\n",
    "  - `Satellite` : discrete (**response variable**)\n",
    "- We gonna treat response variable `Satellite` as binary response (0 or 1).\n",
    "- We need to code number of satellites into 1 for having satellites > 0, and 0 for having satellites = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spine</th>\n",
       "      <th>Width</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Satellite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Color  Spine  Width  Weight  Satellite\n",
       "0      0      2      3   28.3    3.05          1\n",
       "1      1      3      3   26.0    2.60          1\n",
       "2      2      3      3   25.6    2.15          0\n",
       "3      3      4      2   21.0    1.85          0\n",
       "4      4      2      3   29.0    3.00          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code the response variable Satellite\n",
    "# Satellite=0 --> Satellite=0, otherwise Satellite=1\n",
    "data['Satellite'] = data['Satellite'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "# Data check\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross Validation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use resampling methods to estimate Akaike Information Criterion (AIC) from model:\n",
    "$$\n",
    "\\text{logit(satellite)} = \\beta_{0} + \\beta_{1}(\\text{width}) + \\beta_{2}(\\text{weight})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data[['Width', 'Weight']].to_numpy()\n",
    "y = data['Satellite'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AIC (Akaike Information Criterion)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AIC penalizes a model for having many parameters.\n",
    "- The optimal model is the one that tends to have the maximum log likelihood.\n",
    "- That is the model that minimizes:\n",
    "\n",
    "$$\n",
    "\\text{AIC} = -2(\\text{log likelihood - number of parameters in model})\n",
    "$$\n",
    "- When comparing two models, the smaller value of AIC indicates the better model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Validation Set Approach**\n",
    "---\n",
    "**Procedure**:\n",
    "1.  Randomly divide n observations to training set and validation set or hold-out set.\n",
    "2. The model is fit on the training set.\n",
    "3. Calculate AIC on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use `train_test_split` from `sklearn.model.selection` to perform validation set approach.\n",
    "- Find the detail [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- Example:\n",
    "```\n",
    "sklearn.model_selection.train_test_split(Parameters)\n",
    "```\n",
    "- Some of Parameters:\n",
    "  - `test_size`   : float or int, default = `None`\n",
    "  - `train_size`  : float or int, default = `None`\n",
    "  - `shuffle`     : bool, default = `True`\n",
    "- Returns:\n",
    "  - splitting : list, length = 2*len(arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will cross validate AIC score of the model with validation set approach from scratch.\n",
    "\n",
    "Define function `validation_set_split()` to split sample data set based on validation set approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_set_split(X, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to split sample with validation set approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      All predictors set.\n",
    "\n",
    "    random_state : int\n",
    "      Pass an int for reproducible output across multiple function calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_ind_list : list\n",
    "      Contains data index of train set.\n",
    "\n",
    "    valid_ind_list : list\n",
    "      Contains data index of validation set.\n",
    "    \"\"\"\n",
    "    # Extract sample size\n",
    "    n_samples, _ = data.shape\n",
    "\n",
    "    # Set random state (to make it replicable)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Randomize index\n",
    "    random_ind = np.random.choice(n_samples,\n",
    "                                  size = n_samples,\n",
    "                                  replace = False)\n",
    "\n",
    "    # Split data\n",
    "    # First 50% of sample --> validation set\n",
    "    # The remaining is the train set\n",
    "    n_half = int(n_samples / 2)\n",
    "    valid_ind = random_ind[:n_half]\n",
    "    train_ind = random_ind[n_half:]\n",
    "\n",
    "    # Define index list of each set\n",
    "    train_ind_list = [train_ind]\n",
    "    valid_ind_list = [valid_ind]\n",
    "\n",
    "    return train_ind_list, valid_ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Approach\n",
      "n_train = 87\n",
      "n_valid = 86\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "validation_set_index = validation_set_split(X = X,\n",
    "                                            random_state = 42)\n",
    "\n",
    "train_index, valid_index =  validation_set_index\n",
    "\n",
    "# Print train size and valid size\n",
    "print(\"Validation Set Approach\")\n",
    "print(f\"n_train = {np.shape(train_index)[1]}\")\n",
    "print(f\"n_valid = {np.shape(valid_index)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `validation_set_split()` correctly divide your sample of size 173 into train set containing 87 observations and validation set containing 86 observations.\n",
    "\n",
    "Let's check that the train and validation set indexes are random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 81,  79,  84,  39,  98,  86, 117, 168, 145,  47,  94, 138,  61,\n",
      "        73,  33, 165, 152, 135,  62, 171, 109, 112, 105,  53,   5, 127,\n",
      "         3, 160,  49,  35,  80,  77,  34,  46,   7,  43,  70, 132, 110,\n",
      "        91,  83, 155, 156,  89,   8,  13,  59, 148, 131,  17,  72, 159,\n",
      "       134, 144, 158,  63,  54, 107,  50, 170,  58,  48,  88,  21,  57,\n",
      "       167, 129,  37, 163,   1,  52, 149, 130, 151, 103,  99, 116,  87,\n",
      "        74, 121, 172,  20,  71, 106,  14,  92, 102])]\n"
     ]
    }
   ],
   "source": [
    "print(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([162,  42,  90,  60, 114, 137,  41,  15, 113, 108, 124,  82,  78,\n",
      "        38,  31,   9, 111,  56,  24, 153,  93,  45, 146,  29,  55,  65,\n",
      "       143,  19,  16, 141,  30,  18,  12, 139, 115, 154, 136, 147,  51,\n",
      "       126,  66, 119,   2,  97, 169, 150, 164,  85,  26, 157, 166, 101,\n",
      "        68,  36, 133,  22, 142,  95,  67, 100,  11,  76,  75,   6,  27,\n",
      "       125,   4,  32,  69, 118, 161,  10, 104, 120,   0, 140, 122,  64,\n",
      "        44,  96,  28,  40, 123,  25,  23, 128])]\n"
     ]
    }
   ],
   "source": [
    "print(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIC(y_true, y_pred, p):\n",
    "    \"\"\"\n",
    "    Function to split sample with validation set approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : {array-like} of shape (n_sample, )\n",
    "      Actual value of response variable.\n",
    "\n",
    "    y_pred : {array-like} of shape (n_sample, 1)\n",
    "      The success probability of X.\n",
    "\n",
    "    p : int\n",
    "      Number of parameters in model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    aic : float\n",
    "      AIC value.\n",
    "    \"\"\"\n",
    "    # Find the average log likelihood value\n",
    "    llf = np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "\n",
    "    # AIC value is sensitive to number of parameters\n",
    "    # The average log likelihood represent value for 1 unit observation\n",
    "    # AIC from average llf is not comparable\n",
    "    # Multiply llf by n_sample=173 to make its AIC comparable\n",
    "    llf *= 173\n",
    "\n",
    "    # Calculate AIC\n",
    "    aic = -2 * (llf - p)\n",
    "\n",
    "    return aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define function `AIC()` to calculate AIC score of fitted model on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is the llf above is multiplied by 173?**\n",
    "- Note that **AIC** value **from n_train** observations is not comparable, since n_train of one CV method with another can be different.\n",
    "- **We can't compare** that AIC value with other AIC value from model with different number of observations, say we want to compare AIC from validation set (n_valid = 87 observations) with AIC from full sample (n_sample = 173 observations).\n",
    "- Hence, **to make AIC values comparable**, we calculate AIC from log-likelihood value from the same number of observations, we use **n_sample = 173 observations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define function `cross_validate()` to fit a model on train set and calculate its AIC from validation set.\n",
    "\n",
    "We use package from `Statsmodels` to calculate `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pakage\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def cross_validate(X, y, method, cv, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to evaluate AIC by cross-validation method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      The independent variable or predictors.\n",
    "\n",
    "    y : {array-like} of shape (n_sample, )\n",
    "      The dependent or response variable.\n",
    "\n",
    "    method : cross-validation splitter\n",
    "      Cross-validation method.\n",
    "\n",
    "    cv : int\n",
    "      Number of folds for k-Fold CV.\n",
    "\n",
    "    random_state : int, default=42\n",
    "      Pass an int for reproducible output across multiple function calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "      The average AIC score.\n",
    "    \"\"\"\n",
    "    # Split train and valid set based on CV method\n",
    "    if method == \"validation_set\":\n",
    "        train_ind_list, valid_ind_list = validation_set_split(X = X,\n",
    "                                                              random_state = random_state)\n",
    "    elif method == \"loocv\":\n",
    "        train_ind_list, valid_ind_list = loocv_split(X = X)\n",
    "    elif method == \"kfold\":\n",
    "        train_ind_list, valid_ind_list = kfold_split(X = X,\n",
    "                                                     k = cv,\n",
    "                                                     random_state = random_state)\n",
    "\n",
    "    # Define the number of train sets\n",
    "    n_split = len(train_ind_list)\n",
    "\n",
    "    # Initialize AIC score list for each valid set\n",
    "    score_list = []\n",
    "\n",
    "    for i in range(n_split):\n",
    "        # Extract data from index\n",
    "        X_train = X[train_ind_list[i]]\n",
    "        y_train = y[train_ind_list[i]]\n",
    "        X_valid = X[valid_ind_list[i]]\n",
    "        y_valid = y[valid_ind_list[i]]\n",
    "\n",
    "        # Add constant\n",
    "        X_train = sm.add_constant(X_train,\n",
    "                                  has_constant = 'add')\n",
    "        X_valid = sm.add_constant(X_valid,\n",
    "                                  has_constant = 'add')\n",
    "\n",
    "        # Fitting model\n",
    "        model = sm.Logit(y_train, X_train)\n",
    "        results = model.fit(disp = False)\n",
    "\n",
    "        # Calculate success probability\n",
    "        y_pred_train = results.predict(X_train)\n",
    "        y_pred_valid = results.predict(X_valid)\n",
    "\n",
    "        # Calculate AIC\n",
    "        aic_train = AIC(y_true = y_train,\n",
    "                        y_pred = y_pred_train,\n",
    "                        p = X_train.shape[1])\n",
    "        aic_valid = AIC(y_true = y_valid,\n",
    "                        y_pred = y_pred_valid,\n",
    "                        p = X_train.shape[1])\n",
    "\n",
    "        # Append AIC score in list\n",
    "        score_list.append(aic_valid)\n",
    "\n",
    "    # Calculate CV Score\n",
    "    score = np.mean(score_list)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.97299221422074"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the function\n",
    "validation_set_score = cross_validate(X = X,\n",
    "                                      y = y,\n",
    "                                      method = 'validation_set',\n",
    "                                      cv = None,\n",
    "                                      random_state = 42)\n",
    "\n",
    "validation_set_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. LOOCV**\n",
    "---\n",
    "**Procedure**:\n",
    "1. Split n observations into a training set containing all but one observation.\n",
    "2. Validation set is that one observation.\n",
    "3. Model performance is estimated by averaging the n resulting assessment.\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(n)}=\\frac{1}{n}\\sum_{i=1}^{n}\\text{AIC}_{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use `cross_validate` from `sklearn.model.selection` to perform cross-validation.\n",
    "- Find the details [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "- Example:\n",
    "```\n",
    "sklearn.model_selection.cross_validate(Parameters)\n",
    "```\n",
    "- Some of Parameters:\n",
    "  - `estimator` : estimator object implementing ‘fit’ from sklearn\n",
    "  - `X` : array-like of shape (n_samples, n_features)\n",
    "  - `y` : array-like of shape (n_samples,)\n",
    "  - `scoring` : find [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter), default=`None`\n",
    "  - `cv` : int, cross-validation generator or an iterable, default=`None` to use the default 5-fold cross validation.\n",
    "    - You can define other method for parameter `cv`\n",
    "    - Here we use method `LeaveOneOut()` from `sklearn.model.selection`.\n",
    "    - Find the details [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html).\n",
    "    - Note: `LeaveOneOut()` is equivalent to `KFold(n_splits=n)`\n",
    "- Returns:\n",
    "  - scores : dict of float arrays of shape (n_splits,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will cross validate AIC score of the model from scratch.\n",
    "\n",
    "Define function `loocv_split()` to split sample data set based on Leave-One-Out CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv_split(X):\n",
    "    \"\"\"\n",
    "    Function to split sample with leave-one-out cv method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      All predictors set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_ind_list : list\n",
    "      Contains data index of train set.\n",
    "\n",
    "    valid_ind_list : list\n",
    "      Contains data index of validation set.\n",
    "    \"\"\"\n",
    "    # Extract sample size\n",
    "    n_samples, _ = X.shape\n",
    "\n",
    "    # Define initial list for train and valid index\n",
    "    train_ind_list = []\n",
    "    valid_ind_list = []\n",
    "\n",
    "    # Define the number of train and valid sets\n",
    "    # There are n_sample train and valid set\n",
    "    list_ind = [i for i in range(n_samples)]\n",
    "\n",
    "    # Define train and valid index for each set\n",
    "    for i in range(n_samples):\n",
    "        valid_ind = [i]\n",
    "        train_ind = [p for p in list_ind if p not in valid_ind]\n",
    "\n",
    "        # Append train and valid index in list\n",
    "        valid_ind_list.append(valid_ind)\n",
    "        train_ind_list.append(train_ind)\n",
    "\n",
    "    return train_ind_list, valid_ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV for each set from n_sample = 173\n",
      "n_train = 172\n",
      "n_valid = 1\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "loocv_index = loocv_split(X = X)\n",
    "\n",
    "train_index, valid_index =  loocv_index\n",
    "\n",
    "# Print train size and valid size\n",
    "print(\"LOOCV for each set from n_sample = 173\")\n",
    "print(f\"n_train = {np.shape(train_index)[1]}\")\n",
    "print(f\"n_valid = {np.shape(valid_index)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `loocv_split()` correctly divide your sample of size 173.\n",
    "\n",
    "Each sample is used once as a test set (`n_valid = 1`) while the remaining samples form the training set (`n_train = 172`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2   3 ... 170 171 172]\n",
      " [  0   2   3 ... 170 171 172]\n",
      " [  0   1   3 ... 170 171 172]\n",
      " ...\n",
      " [  0   1   2 ... 169 171 172]\n",
      " [  0   1   2 ... 169 170 172]\n",
      " [  0   1   2 ... 169 170 171]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0]\n",
      " [  1]\n",
      " [  2]\n",
      " [  3]\n",
      " [  4]\n",
      " [  5]\n",
      " [  6]\n",
      " [  7]\n",
      " [  8]\n",
      " [  9]\n",
      " [ 10]\n",
      " [ 11]\n",
      " [ 12]\n",
      " [ 13]\n",
      " [ 14]\n",
      " [ 15]\n",
      " [ 16]\n",
      " [ 17]\n",
      " [ 18]\n",
      " [ 19]\n",
      " [ 20]\n",
      " [ 21]\n",
      " [ 22]\n",
      " [ 23]\n",
      " [ 24]\n",
      " [ 25]\n",
      " [ 26]\n",
      " [ 27]\n",
      " [ 28]\n",
      " [ 29]\n",
      " [ 30]\n",
      " [ 31]\n",
      " [ 32]\n",
      " [ 33]\n",
      " [ 34]\n",
      " [ 35]\n",
      " [ 36]\n",
      " [ 37]\n",
      " [ 38]\n",
      " [ 39]\n",
      " [ 40]\n",
      " [ 41]\n",
      " [ 42]\n",
      " [ 43]\n",
      " [ 44]\n",
      " [ 45]\n",
      " [ 46]\n",
      " [ 47]\n",
      " [ 48]\n",
      " [ 49]\n",
      " [ 50]\n",
      " [ 51]\n",
      " [ 52]\n",
      " [ 53]\n",
      " [ 54]\n",
      " [ 55]\n",
      " [ 56]\n",
      " [ 57]\n",
      " [ 58]\n",
      " [ 59]\n",
      " [ 60]\n",
      " [ 61]\n",
      " [ 62]\n",
      " [ 63]\n",
      " [ 64]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 83]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 86]\n",
      " [ 87]\n",
      " [ 88]\n",
      " [ 89]\n",
      " [ 90]\n",
      " [ 91]\n",
      " [ 92]\n",
      " [ 93]\n",
      " [ 94]\n",
      " [ 95]\n",
      " [ 96]\n",
      " [ 97]\n",
      " [ 98]\n",
      " [ 99]\n",
      " [100]\n",
      " [101]\n",
      " [102]\n",
      " [103]\n",
      " [104]\n",
      " [105]\n",
      " [106]\n",
      " [107]\n",
      " [108]\n",
      " [109]\n",
      " [110]\n",
      " [111]\n",
      " [112]\n",
      " [113]\n",
      " [114]\n",
      " [115]\n",
      " [116]\n",
      " [117]\n",
      " [118]\n",
      " [119]\n",
      " [120]\n",
      " [121]\n",
      " [122]\n",
      " [123]\n",
      " [124]\n",
      " [125]\n",
      " [126]\n",
      " [127]\n",
      " [128]\n",
      " [129]\n",
      " [130]\n",
      " [131]\n",
      " [132]\n",
      " [133]\n",
      " [134]\n",
      " [135]\n",
      " [136]\n",
      " [137]\n",
      " [138]\n",
      " [139]\n",
      " [140]\n",
      " [141]\n",
      " [142]\n",
      " [143]\n",
      " [144]\n",
      " [145]\n",
      " [146]\n",
      " [147]\n",
      " [148]\n",
      " [149]\n",
      " [150]\n",
      " [151]\n",
      " [152]\n",
      " [153]\n",
      " [154]\n",
      " [155]\n",
      " [156]\n",
      " [157]\n",
      " [158]\n",
      " [159]\n",
      " [160]\n",
      " [161]\n",
      " [162]\n",
      " [163]\n",
      " [164]\n",
      " [165]\n",
      " [166]\n",
      " [167]\n",
      " [168]\n",
      " [169]\n",
      " [170]\n",
      " [171]\n",
      " [172]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(valid_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate AIC score with `cross_validate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204.72220473824714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate CV score\n",
    "loocv_score = cross_validate(X = X,\n",
    "                             y = y,\n",
    "                             method = 'loocv',\n",
    "                             cv = None,\n",
    "                             random_state = 42)\n",
    "\n",
    "loocv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. k-Fold CV**\n",
    "---\n",
    "**Procedure**:\n",
    "1. Randomly divide n observations into $k$ groups ($k$ folds) of approximately equal size,\n",
    "typically $k=5$ or $k=10$.\n",
    "2. Choose one fold as a validation set,\n",
    "and the remainder $k-1$ folds as training set.\n",
    "3. Fit model in training set,\n",
    "assess the fitted model in validation set.\n",
    "Repeat step 2 and 3 until $k$ times.\n",
    "4. The $k$-fold CV estimate is computed\n",
    "by averaging model performance\n",
    "from step 3.\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(k)}=\\frac{1}{k}\\sum_{i=1}^{k}\\text{AIC}_{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use `cross_validate` from `sklearn.model.selection` to perform k-Fold cross-validation.\n",
    "- Find the details [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "- Example:\n",
    "```\n",
    "sklearn.model_selection.cross_validate(Parameters)\n",
    "```\n",
    "- Some of Parameters:\n",
    "  - `estimator` : estimator object implementing ‘fit’ from sklearn\n",
    "  - `X` : array-like of shape (n_samples, n_features)\n",
    "  - `y` : array-like of shape (n_samples,)\n",
    "  - `scoring` : find [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter), default=`None`\n",
    "  - `cv` : int, cross-validation generator or an iterable, default=`None` to use the default 5-fold cross validation.\n",
    "    - You can define other method for parameter `cv`\n",
    "    - Here we use method `kFold` from `sklearn.model.selection`.\n",
    "    - Find the details [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold).\n",
    "    - Example:\n",
    "    ```\n",
    "    KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "    ```\n",
    "- Returns:\n",
    "  - scores : dict of float arrays of shape (n_splits,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will cross validate AIC score of the model from scratch.\n",
    "\n",
    "Define function `kfold_split()` to split sample data set based on k-Fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_split(X, k=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to split sample with validation set approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      All predictors set.\n",
    "\n",
    "    k : int, default = 5\n",
    "      Number of folds.\n",
    "\n",
    "    random_state : int\n",
    "      Pass an int for reproducible output across multiple function calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_ind_list : list\n",
    "      Contains data index of train set.\n",
    "\n",
    "    valid_ind_list : list\n",
    "      Contains data index of validation set.\n",
    "    \"\"\"\n",
    "    # Extract sample size\n",
    "    n_samples, _ = data.shape\n",
    "\n",
    "    # Set random state\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # # Randomize index\n",
    "    random_ind = np.random.choice(n_samples,\n",
    "                                  size = n_samples,\n",
    "                                  replace = False)\n",
    "\n",
    "    # Calculate size of each fold\n",
    "    fold_sizes = np.ones(k, dtype=int) * (n_samples//k)\n",
    "    fold_sizes[:n_samples%k] += 1\n",
    "\n",
    "    # Define initial list for each train and valid index\n",
    "    train_ind_list = []\n",
    "    valid_ind_list = []\n",
    "\n",
    "    # Split sample\n",
    "    current_ind = 0\n",
    "    for size in fold_sizes:\n",
    "        # Define index\n",
    "        start_ind = current_ind\n",
    "        end_ind = current_ind + size\n",
    "\n",
    "        # Slice valid set\n",
    "        # One fold for valid set, the remaining for train set\n",
    "        valid_ind = random_ind[start_ind:end_ind]\n",
    "        train_ind = np.concatenate((random_ind[:start_ind],\n",
    "                                    random_ind[end_ind:]))\n",
    "\n",
    "        # Update current index\n",
    "        current_ind = end_ind\n",
    "\n",
    "        # Append train and valid index in list\n",
    "        train_ind_list.append(train_ind)\n",
    "        valid_ind_list.append(valid_ind)\n",
    "\n",
    "    return train_ind_list, valid_ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV for each set from k_sample set\n",
      "n_train = 155\n",
      "n_valid = 18\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "kfold_index = kfold_split(X = X,\n",
    "                          k = 10,\n",
    "                          random_state = 42)\n",
    "\n",
    "train_index, valid_index =  kfold_index\n",
    "\n",
    "# Print train size and valid size\n",
    "print(\"10-Fold CV for each set from k_sample set\")\n",
    "print(f\"n_train = {len(train_index[0])}\")\n",
    "print(f\"n_valid = {len(valid_index[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `kfold_split()` correctly divide your sample of size 173 into 10 folds.\n",
    "\n",
    "Each fold is used once as a test set (`n_valid = 18`) while the remaining folds form the training set (`n_train = 155`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate AIC score with `cross_validate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203.0843746327386"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate CV score\n",
    "kfold_score = cross_validate(X = X,\n",
    "                             y = y,\n",
    "                             method = 'kfold',\n",
    "                             cv = 10,\n",
    "                             random_state = 42)\n",
    "\n",
    "kfold_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CV Summary**\n",
    "---\n",
    "Table below summarize the CV Score (AIC) from Model 2 using three methods of cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>AIC Valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation_set</td>\n",
       "      <td>218.972992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loocv</td>\n",
       "      <td>204.722205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kfold</td>\n",
       "      <td>203.084375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           method   AIC Valid\n",
       "0  validation_set  218.972992\n",
       "1           loocv  204.722205\n",
       "2           kfold  203.084375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define three methods of CV in method_list\n",
    "method_list = [\"validation_set\", \"loocv\", \"kfold\"]\n",
    "\n",
    "# Create initial list for AIC score of each method\n",
    "score_list = []\n",
    "\n",
    "# Calculate AIC score for each method in list\n",
    "for method in method_list:\n",
    "    score = cross_validate(X = X,\n",
    "                           y = y,\n",
    "                           method = method,\n",
    "                           cv = 10,\n",
    "                           random_state = 42)\n",
    "    score_list.append(score)\n",
    "\n",
    "# Tabulate each method and its AIC score\n",
    "summary_df = pd.DataFrame({\"method\": method_list,\n",
    "                           \"AIC Valid\": score_list})\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Selection**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spine</th>\n",
       "      <th>Width</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Satellite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Color  Spine  Width  Weight  Satellite\n",
       "0      0      2      3   28.3    3.05          1\n",
       "1      1      3      3   26.0    2.60          1\n",
       "2      2      3      3   25.6    2.15          0\n",
       "3      3      4      2   21.0    1.85          0\n",
       "4      4      2      3   29.0    3.00          1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data check\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use all 4 predictors in model selection.\n",
    "- Color : ordinal (treated as continuous)\n",
    "- Spine : multicategory\n",
    "- Width : continuous\n",
    "- Weight : continuous\n",
    "\n",
    "We have one multicategory predictor Spine, we need dummies for Spine, where:\n",
    "- Spine = 1 as the reference\n",
    "- Dummies for:\n",
    "  - Spine_2\n",
    "  - Spine_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spine</th>\n",
       "      <th>Width</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Satellite</th>\n",
       "      <th>Spine_2</th>\n",
       "      <th>Spine_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Color  Spine  Width  Weight  Satellite  Spine_2  Spine_3\n",
       "0      0      2      3   28.3    3.05          1        0        1\n",
       "1      1      3      3   26.0    2.60          1        0        1\n",
       "2      2      3      3   25.6    2.15          0        0        1\n",
       "3      3      4      2   21.0    1.85          0        1        0\n",
       "4      4      2      3   29.0    3.00          1        0        1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for Spine_2 and Spine_3\n",
    "data[['Spine_2', 'Spine_3']] = pd.get_dummies(data['Spine'],\n",
    "                                              dtype = 'int',\n",
    "                                              drop_first = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **5 predictors** for model selection.\n",
    "- Width : continuous\n",
    "- Weight : continuous\n",
    "- Color : continuous (ordinal)\n",
    "- Dummy Spine_2 : category\n",
    "- Dummy Spine_3 : category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.3 ,  3.05,  2.  ,  0.  ,  1.  ],\n",
       "       [26.  ,  2.6 ,  3.  ,  0.  ,  1.  ],\n",
       "       [25.6 ,  2.15,  3.  ,  0.  ,  1.  ],\n",
       "       [21.  ,  1.85,  4.  ,  1.  ,  0.  ],\n",
       "       [29.  ,  3.  ,  2.  ,  0.  ,  1.  ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define predictors X and response y\n",
    "X = data[['Width', 'Weight', 'Color', 'Spine_2', 'Spine_3']].to_numpy()\n",
    "y = data['Satellite'].to_numpy()\n",
    "\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Best Subset Selection**\n",
    "---\n",
    "Fit a separate model for each possible combination of the $p$ predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function `best_subset()` to fit a model on train set and calculate its AIC from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_subset(X, y, k, predictors, method, cv=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to perform best subset selection procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      All predictors set.\n",
    "\n",
    "    y : {array-like} of shape (n_sample, )\n",
    "      The dependent or response variable.\n",
    "\n",
    "    k : int\n",
    "      Number of predictors included in model.\n",
    "\n",
    "    predictors : {array-like} of shape (n_sample, )\n",
    "      Index of predictors\n",
    "\n",
    "    method : cross-validation splitter\n",
    "      Cross-validation method.\n",
    "\n",
    "    cv : int, default=5\n",
    "      Number of folds for k-Fold CV.\n",
    "\n",
    "    random_state : int, default=42\n",
    "      Pass an int for reproducible output across multiple function calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models : {array-like} of shape (n_combinations, k)\n",
    "      Summary of predictors and its AIC score for each possible combination.\n",
    "\n",
    "    best_model : {array-like} of shape (2, )\n",
    "      Best model of models with the smallest AIC score.\n",
    "    \"\"\"\n",
    "    # Initialize list of results\n",
    "    results = []\n",
    "\n",
    "    # Define sample size and  number of all predictors\n",
    "    n_samples, n_predictors = X.shape\n",
    "\n",
    "    # Initialize list of predictors and its CV Score\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    # Iteratively cross validate each possible combination of k\n",
    "    for combi in itertools.combinations(predictors, k):\n",
    "        # Extract predictors combination\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        # Cross validate to get CV Score\n",
    "        score_ = cross_validate(X = X_,\n",
    "                                y = y_,\n",
    "                                method = method,\n",
    "                                cv = cv,\n",
    "                                random_state = random_state)\n",
    "\n",
    "        # Append predictors combination and its CV Score to the list\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    # Tabulate the results\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                            \"AIC\": score_list})\n",
    "\n",
    "    # Choose the best model of k predictors\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the function for `k=2` predictors included in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all predictors\n",
    "n_predictors = X.shape[1]\n",
    "predictors = np.arange(n_predictors)\n",
    "\n",
    "# Perform best subset selection for k=2 predictors in model\n",
    "models_2, best_model_2 = best_subset(X = X,\n",
    "                                     y = y,\n",
    "                                     k = 2,\n",
    "                                     predictors = predictors,\n",
    "                                     method = 'kfold',\n",
    "                                     cv = 10,\n",
    "                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>203.084375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>199.810140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>205.807050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>204.926291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>200.691316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>206.889344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>205.945171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>222.548089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>221.674235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>234.627975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predictors         AIC\n",
       "0     [0, 1]  203.084375\n",
       "1     [0, 2]  199.810140\n",
       "2     [0, 3]  205.807050\n",
       "3     [0, 4]  204.926291\n",
       "4     [1, 2]  200.691316\n",
       "5     [1, 3]  206.889344\n",
       "6     [1, 4]  205.945171\n",
       "7     [2, 3]  222.548089\n",
       "8     [2, 4]  221.674235\n",
       "9     [3, 4]  234.627975"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print results of each possible combination\n",
    "models_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including 2 of 5 predictors in model yields 10 possible combinations since $C(5,2)=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predictors       [0, 2]\n",
       "AIC           199.81014\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best model of 2 predictors included in model\n",
    "# The best model is the model with smallest AIC\n",
    "best_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `k=2` predictors in model, the best model is the model with predictors with index [0, 2] in X, which is variable Width and Color, with AIC value of 199.81.\n",
    "\n",
    "Next, perform the best subset model selection procedure for all possible combinations in each `k` predictors included in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for the best model of each k predictors\n",
    "best_subset_models = pd.DataFrame(columns = [\"Predictors\", \"AIC\"])\n",
    "\n",
    "# Define all predictors\n",
    "n_predictors = X.shape[1]\n",
    "predictors = np.arange(n_predictors)\n",
    "\n",
    "# Perform best subset selection procedure\n",
    "for k in range(n_predictors+1):\n",
    "    _, best_model = best_subset(X = X,\n",
    "                                y = y,\n",
    "                                k = k,\n",
    "                                predictors = predictors,\n",
    "                                method = 'kfold',\n",
    "                                cv = 10,\n",
    "                                random_state = 42)\n",
    "\n",
    "    # Tabulate the best model of each k predictors\n",
    "    best_subset_models.loc[k] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>229.286353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0]</td>\n",
       "      <td>201.540786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>199.81014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>201.616479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 4]</td>\n",
       "      <td>203.771348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>207.266894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predictors         AIC\n",
       "0               []  229.286353\n",
       "1              [0]  201.540786\n",
       "2           [0, 2]   199.81014\n",
       "3        [0, 1, 2]  201.616479\n",
       "4     [0, 1, 2, 4]  203.771348\n",
       "5  [0, 1, 2, 3, 4]  207.266894"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best model of each k predictors\n",
    "best_subset_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "> - The smallest AIC score from 10-fold cross-validation is 199.81 for model with `k=2` predictors.\n",
    "> - Thus, with best subset selection procedure, the best logistic regression model for horseshoe crab sample is model with 2 predictors, which is the model with predictors Width and Color.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546593\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  173\n",
      "Model:                          Logit   Df Residuals:                      170\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 08 Nov 2024   Pseudo R-squ.:                  0.1623\n",
      "Time:                        04:06:32   Log-Likelihood:                -94.561\n",
      "converged:                       True   LL-Null:                       -112.88\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.107e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.0708      2.807     -3.588      0.000     -15.572      -4.569\n",
      "x1             0.4583      0.104      4.406      0.000       0.254       0.662\n",
      "x2            -0.5090      0.224     -2.276      0.023      -0.947      -0.071\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define column index of best predictors\n",
    "best_predictors = best_subset_models.loc[2]['Predictors']\n",
    "\n",
    "# Define X with best predictors\n",
    "X_best = X[:, [0,2]]\n",
    "\n",
    "# Fit best model\n",
    "X_best = sm.add_constant(X_best)\n",
    "best_model = sm.Logit(y, X_best)\n",
    "best_model_result = best_model.fit()\n",
    "\n",
    "print(best_model_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Forward Selection**\n",
    "---\n",
    "Begin with null model (no predictors), then adds predictors that gives the greatest additional improvement to the model, one-at-a-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function `forward()` to fit a model on train set and calculate its AIC from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, y, predictors, method, cv=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to perform best subset selection procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      All predictors set.\n",
    "\n",
    "    y : {array-like} of shape (n_sample, )\n",
    "      The dependent or response variable.\n",
    "\n",
    "    predictors : {array-like} of shape (n_sample, )\n",
    "      Index of predictors\n",
    "\n",
    "    method : cross-validation splitter\n",
    "      Cross-validation method.\n",
    "\n",
    "    cv : int, default=5\n",
    "      Number of folds for k-Fold CV.\n",
    "\n",
    "    random_state : int, default=42\n",
    "      Pass an int for reproducible output across multiple function calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models : {array-like} of shape (n_combinations, k)\n",
    "      Summary of predictors and its AIC score for each possible combination.\n",
    "\n",
    "    best_model : {array-like} of shape (2, )\n",
    "      Best model of models with the smallest AIC score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list of results\n",
    "    results = []\n",
    "\n",
    "    # Define sample size and  number of all predictors\n",
    "    n_samples, n_predictors = X.shape\n",
    "\n",
    "    # Define list of all predictors\n",
    "    col_list = np.arange(n_predictors)\n",
    "\n",
    "    # Define remaining predictors for each k\n",
    "    remaining_predictors = [p for p in col_list if p not in predictors]\n",
    "\n",
    "    # Initialize list of predictors and its CV Score\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    # Cross validate each possible combination of remaining predictors\n",
    "    for p in remaining_predictors:\n",
    "        combi = predictors + [p]\n",
    "\n",
    "        # Extract predictors combination\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        # Cross validate to get CV Score\n",
    "        score_ = cross_validate(X = X_,\n",
    "                                y = y_,\n",
    "                                method = method,\n",
    "                                cv = cv,\n",
    "                                random_state = random_state)\n",
    "\n",
    "        # Append predictors combination and its CV Score to the list\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    # Tabulate the results\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                            \"AIC\": score_list})\n",
    "\n",
    "    # Choose the best model\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the forward selection procedure for all possible combinations in each `k` predictors included in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit null model\n",
    "predictor = []\n",
    "score_ = cross_validate(X = X[:,predictor],\n",
    "                        y = y,\n",
    "                        method = 'kfold',\n",
    "                        cv = 10,\n",
    "                        random_state = 42)\n",
    "\n",
    "# Create table for the best model of each k predictors\n",
    "# Append the results of null model\n",
    "forward_models = pd.DataFrame({\"Predictors\": [predictor],\n",
    "                               \"AIC\": [score_]})\n",
    "\n",
    "# Define list of predictors\n",
    "predictors = []\n",
    "n_predictors = X.shape[1]\n",
    "\n",
    "# Perform forward selection procedure for k=1,...,5 predictors\n",
    "for k in range(n_predictors):\n",
    "    _, best_model = forward(X = X,\n",
    "                            y = y,\n",
    "                            predictors = predictors,\n",
    "                            method = 'kfold',\n",
    "                            cv = 10,\n",
    "                            random_state = 42)\n",
    "\n",
    "    # Tabulate the best model of each k predictors\n",
    "    forward_models.loc[k+1] = best_model\n",
    "    predictors = best_model['Predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>229.286353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0]</td>\n",
       "      <td>201.540786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>199.810140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 2, 1]</td>\n",
       "      <td>201.616479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 2, 1, 4]</td>\n",
       "      <td>203.771348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 2, 1, 4, 3]</td>\n",
       "      <td>207.266894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predictors         AIC\n",
       "0               []  229.286353\n",
       "1              [0]  201.540786\n",
       "2           [0, 2]  199.810140\n",
       "3        [0, 2, 1]  201.616479\n",
       "4     [0, 2, 1, 4]  203.771348\n",
       "5  [0, 2, 1, 4, 3]  207.266894"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best model of each k predictors\n",
    "forward_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "> - The smallest AIC score from 10-fold cross-validation is 199.81 for model with `k=2` predictors.\n",
    "> - Thus, with forward selection procedure, the best logistic regression model for horseshoe crab sample is model with 2 predictors, which is the model with predictors Width and Color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546593\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  173\n",
      "Model:                          Logit   Df Residuals:                      170\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 08 Nov 2024   Pseudo R-squ.:                  0.1623\n",
      "Time:                        04:07:31   Log-Likelihood:                -94.561\n",
      "converged:                       True   LL-Null:                       -112.88\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.107e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.0708      2.807     -3.588      0.000     -15.572      -4.569\n",
      "x1             0.4583      0.104      4.406      0.000       0.254       0.662\n",
      "x2            -0.5090      0.224     -2.276      0.023      -0.947      -0.071\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define column index of best predictors\n",
    "best_predictors = forward_models.loc[2]['Predictors']\n",
    "\n",
    "# Define X with best predictors\n",
    "X_best = X[:, [0,2]]\n",
    "\n",
    "# Fit best model\n",
    "X_best = sm.add_constant(X_best)\n",
    "best_model = sm.Logit(y, X_best)\n",
    "best_model_result = best_model.fit()\n",
    "\n",
    "print(best_model_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Backward Elimination**\n",
    "---\n",
    "Begin with the full model containing all p predictors,\n",
    "and then iteratively removes the least useful predictor, one-at-a-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function `backward()` to fit a model on train set and calculate its AIC from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, y, predictors, method, cv=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to perform best subset selection procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like} of shape (n_sample, n_predictors)\n",
    "      All predictors set.\n",
    "\n",
    "    y : {array-like} of shape (n_sample, )\n",
    "      The dependent or response variable.\n",
    "\n",
    "    predictors : {array-like} of shape (n_sample, )\n",
    "      Index of predictors\n",
    "\n",
    "    method : cross-validation splitter\n",
    "      Cross-validation method.\n",
    "\n",
    "    cv : int, default=5\n",
    "      Number of folds for k-Fold CV.\n",
    "\n",
    "    random_state : int, default=42\n",
    "      Pass an int for reproducible output across multiple function calls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models : {array-like} of shape (n_combinations, k)\n",
    "      Summary of predictors and its AIC score for each possible combination.\n",
    "\n",
    "    best_model : {array-like} of shape (2, )\n",
    "      Best model of models with the smallest AIC score.\n",
    "    \"\"\"\n",
    "    # Initialize list of results\n",
    "    results = []\n",
    "\n",
    "    # Initialize list of predictors and its CV Score\n",
    "    pred_list = []\n",
    "    score_list = []\n",
    "\n",
    "    # Cross validate each possible combination of remaining predictors\n",
    "    for combi in itertools.combinations(predictors, len(predictors)-1):\n",
    "\n",
    "        # Extract predictors combination\n",
    "        X_ = X[:, combi]\n",
    "        y_ = y\n",
    "\n",
    "        # Cross validate to get CV Score\n",
    "        score_ = cross_validate(X = X_,\n",
    "                                y = y_,\n",
    "                                method = method,\n",
    "                                cv = cv,\n",
    "                                random_state = random_state)\n",
    "\n",
    "        # Append predictors combination and its CV Score to the list\n",
    "        pred_list.append(list(combi))\n",
    "        score_list.append(score_)\n",
    "\n",
    "    # Tabulate the results\n",
    "    models = pd.DataFrame({\"Predictors\": pred_list,\n",
    "                            \"AIC\": score_list})\n",
    "\n",
    "    # Choose the best model\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "\n",
    "    return models, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the backward elimination procedure for all possible combinations of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit full model\n",
    "n_predictors = X.shape[1]\n",
    "predictors = np.arange(n_predictors)\n",
    "score_ = cross_validate(X = X[:, predictors],\n",
    "                        y = y,\n",
    "                        method = 'kfold',\n",
    "                        cv = 10,\n",
    "                        random_state = 42)\n",
    "\n",
    "# Create table for the best model of each combination of predictors\n",
    "# Append the results of the full model\n",
    "backward_models = pd.DataFrame({\"Predictors\": [predictors],\n",
    "                               \"AIC\": [score_]})\n",
    "\n",
    "# Define initial k=1, to eliminate 1 predictor\n",
    "k=1\n",
    "\n",
    "# Perform backward eliminiation procedure\n",
    "while(len(predictors) > 0):\n",
    "    _, best_model = backward(X = X,\n",
    "                             y = y,\n",
    "                             predictors = predictors,\n",
    "                             method = 'kfold',\n",
    "                             cv = 10,\n",
    "                             random_state = 42)\n",
    "\n",
    "    # Tabulate the best model of each combination of predictors\n",
    "    backward_models.loc[k] = best_model\n",
    "    predictors = best_model[\"Predictors\"]\n",
    "\n",
    "    # Define next iteration\n",
    "    # Iteratively eliminate 1 predictor\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictors</th>\n",
       "      <th>AIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>207.266894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 4]</td>\n",
       "      <td>203.771348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>201.616479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>199.810140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0]</td>\n",
       "      <td>201.540786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "      <td>229.286353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predictors         AIC\n",
       "0  [0, 1, 2, 3, 4]  207.266894\n",
       "1     [0, 1, 2, 4]  203.771348\n",
       "2        [0, 1, 2]  201.616479\n",
       "3           [0, 2]  199.810140\n",
       "4              [0]  201.540786\n",
       "5               []  229.286353"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best model of each combination of predictors\n",
    "backward_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "> - The smallest AIC score from 10-fold cross-validation is 199.81 for model with 2 predictors.\n",
    "> - Thus, with backward elimination procedure, the best logistic regression model for horseshoe crab sample is model with 2 predictors, which is the model with predictors Width and Color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546593\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  173\n",
      "Model:                          Logit   Df Residuals:                      170\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Fri, 08 Nov 2024   Pseudo R-squ.:                  0.1623\n",
      "Time:                        04:08:31   Log-Likelihood:                -94.561\n",
      "converged:                       True   LL-Null:                       -112.88\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.107e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.0708      2.807     -3.588      0.000     -15.572      -4.569\n",
      "x1             0.4583      0.104      4.406      0.000       0.254       0.662\n",
      "x2            -0.5090      0.224     -2.276      0.023      -0.947      -0.071\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define column index of best predictors\n",
    "best_predictors = backward_models.loc[2]['Predictors']\n",
    "\n",
    "# Define X with best predictors\n",
    "X_best = X[:, [0,2]]\n",
    "\n",
    "# Fit best model\n",
    "X_best = sm.add_constant(X_best)\n",
    "best_model = sm.Logit(y, X_best)\n",
    "best_model_result = best_model.fit()\n",
    "\n",
    "print(best_model_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Selection Summary**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three model selection methods yield the same conclusion of which combination of predictors yields the smallest AIC score.\n",
    "\n",
    "**Best Subset Selection Advantage**\n",
    "- Simple procedure.\n",
    "- It yields a larger search space, which means a higher chance of finding the best model.\n",
    "\n",
    "**Best Subset Selection Drawbacks**\n",
    "- Can't be applied with very large $p$ (number of predictors), since **we have to fit $2^{p}$ models**.\n",
    "- It may also suffer from statistical problems when $p$ is large.\n",
    "  - The larger the search space, the higher the chance of finding models that look good on the training data, even though they might not have any predictive power on future data.\n",
    "\n",
    "**Stepwise Methods Advantage**\n",
    "- The only viable subset method when $p$ is very large.\n",
    "- Forward selection can be used even when $n < p$.\n",
    "\n",
    "**Stepwise Methods Drawbacks**\n",
    "- Backward selection requires that sample size $n$ is larger than number of predictors $p$ (so that the full model can be fit).\n",
    "- Stepwise methods is **not guaranteed to yield the best\n",
    "model** containing a subset of the $p$ predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
